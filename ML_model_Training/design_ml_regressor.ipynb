{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfad282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'E:\\MS_AI\\BKW_hack\\BKW-Design-Agent\\ML_model\\data\\extracted_historical_data_04.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"CSV file loaded successfully!\")\n",
    "    display(data.head()) # Display the first few rows to confirm\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b20045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9557050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Feature Selection and Preprocessing ---\n",
    "features = ['L (mm)', 'Material', 'h (mm)', 'w (mm)', 'F (N)']\n",
    "target = 'Deflection (mm)'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# FIX #1: Use .loc to avoid the SettingWithCopyWarning\n",
    "X.loc[:, 'Material'] = label_encoder.fit_transform(X['Material'])\n",
    "\n",
    "# --- 3. Splitting and Scaling ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the scaler ONLY on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- 4. Training the Model ---\n",
    "# The model is trained on the scaled data\n",
    "model = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "\n",
    "# model = RandomForestRegressor(\n",
    "#     n_estimators=400,          # 400 is a good number of trees, we can keep it.\n",
    "#     max_depth=15,              # *** MOST IMPORTANT ***: Prevents trees from growing too deep.\n",
    "#     min_samples_leaf=5,        # *** IMPORTANT ***: Ensures each final prediction is based on at least 5 samples.\n",
    "#     max_features='sqrt',       # *** IMPORTANT ***: Reduces correlation between trees by using a subset of features.\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1                  # Use all available CPU cores to speed up training.\n",
    "# )\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- 5. Thorough Performance Evaluation ---\n",
    "print(\"--- Model Performance Evaluation ---\")\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f\"Test Set Mean Absolute Error (MAE): {mae_test:.2f} mm\")\n",
    "print(f\"Test Set Root Mean Squared Error (RMSE): {rmse_test:.2f} mm\")\n",
    "print(f\"Test Set Mean Squared Error (MSE): {mse_test:.2f}\")\n",
    "\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(f\"Train Set Mean Squared Error on Training Data: {mse_train:.2f}\")\n",
    "\n",
    "# --- 6. Saving the Trained Model and Preprocessors ---\n",
    "print(\"\\n--- Saving Model and Preprocessors ---\")\n",
    "joblib.dump(model, 'random_forest_deflection_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "print(\"Model, scaler, and label encoder saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Loading the Saved Model and Preprocessors ---\n",
    "print(\"\\n--- Loading Model and Preprocessors for Inference ---\")\n",
    "loaded_model = joblib.load('random_forest_deflection_model.joblib')\n",
    "loaded_scaler = joblib.load('scaler.joblib')\n",
    "loaded_label_encoder = joblib.load('label_encoder.joblib')\n",
    "print(\"Assets loaded successfully.\")\n",
    "\n",
    "# --- 8. Prediction Function using LOADED Assets ---\n",
    "def predict_with_loaded_model(length, material, height, width, force):\n",
    "    \"\"\"\n",
    "    Predicts deflection using the loaded model and preprocessors.\n",
    "    \"\"\"\n",
    "    new_data = pd.DataFrame({\n",
    "        'L (mm)': [length], 'Material': [material], 'h (mm)': [height], 'w (mm)': [width], 'F (N)': [force]\n",
    "    })\n",
    "    # Use the loaded encoder and scaler\n",
    "    new_data['Material'] = loaded_label_encoder.transform(new_data['Material'])\n",
    "    new_data_scaled = loaded_scaler.transform(new_data)\n",
    "    \n",
    "    # Predict using the loaded model\n",
    "    predicted_deflection = loaded_model.predict(new_data_scaled)[0]\n",
    "    \n",
    "    allowable_deflection = length / 240\n",
    "    status = \"PASS\" if predicted_deflection < allowable_deflection else \"FAIL\"\n",
    "\n",
    "    print(f\"\\n--- Prediction using LOADED Model ---\")\n",
    "    print(f\"Input Length: {length} mm\")\n",
    "    print(f\"Predicted Deflection: {predicted_deflection:.2f} mm\")\n",
    "    print(f\"Allowable Deflection: {allowable_deflection:.2f} mm\")\n",
    "    print(f\"Status: {status}\")\n",
    "\n",
    "predict_with_loaded_model(length=2500, material='Steel', height=80, width=46, force=10000)\n",
    "predict_with_loaded_model(length=1200, material='Steel', height=80, width=46, force=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73fae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"R-squared (R²) Score: {r2:.4f}\")\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.2f} mm\")\n",
    "print(\"\\n--- 'Proxy' Pass/Fail Accuracy ---\")\n",
    "\n",
    "# To calculate accuracy, we need the original unscaled Lengths from the test set\n",
    "X_test_unscaled = scaler.inverse_transform(X_test_scaled)\n",
    "X_test_unscaled_df = pd.DataFrame(X_test_unscaled, columns=X_train.columns)\n",
    "\n",
    "# Determine \"Actual Status\" and \"Predicted Status\"\n",
    "allowable_deflection = X_test_unscaled_df['L (mm)'] / 240\n",
    "\n",
    "# FIX: Use .values to compare the underlying numpy arrays, ignoring the pandas index\n",
    "actual_status = np.where(y_test.values < allowable_deflection.values, 'PASS', 'FAIL')\n",
    "# y_pred_test is already a numpy array, so we only need .values on allowable_deflection\n",
    "predicted_status = np.where(y_pred_test < allowable_deflection.values, 'PASS', 'FAIL')\n",
    "\n",
    "# Calculate the accuracy of the final Pass/Fail decision\n",
    "pass_fail_accuracy = accuracy_score(actual_status, predicted_status)\n",
    "print(f\"Pass/Fail Decision Accuracy: {pass_fail_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa821cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
    "\n",
    "def evaluate_model(test_data):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model and its preprocessors to evaluate performance\n",
    "    on a new, unseen dataset.\n",
    "\n",
    "    Args:\n",
    "        data_filepath (str): The path to the new CSV data file.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Pre-trained Assets ---\n",
    "    print(\"--- Loading Pre-trained Model and Preprocessors ---\")\n",
    "    try:\n",
    "        model = joblib.load('random_forest_deflection_model.joblib')\n",
    "        scaler = joblib.load('scaler.joblib')\n",
    "        label_encoder = joblib.load('label_encoder.joblib')\n",
    "        print(\"Assets loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file. Make sure model, scaler, and encoder files are in the same directory.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return # Exit the function if files are missing\n",
    "\n",
    "    new_df = test_data\n",
    "    \n",
    "    \n",
    "\n",
    "    # Define the expected feature and target columns\n",
    "    features = ['L (mm)', 'Material', 'h (mm)', 'w (mm)', 'F (N)']\n",
    "    target = 'Deflection (mm)'\n",
    "\n",
    "    # Ensure all required columns are present in the new data\n",
    "    required_columns = features + [target]\n",
    "    if not all(col in new_df.columns for col in required_columns):\n",
    "        print(f\"Error: The new data file is missing one or more required columns. Required: {required_columns}\")\n",
    "        return\n",
    "\n",
    "    X_new = new_df[features].copy()\n",
    "    y_new = new_df[target]\n",
    "\n",
    "    # --- 3. Preprocess New Data using LOADED Assets ---\n",
    "    # IMPORTANT: Use the loaded preprocessors to transform the data. DO NOT refit them.\n",
    "    \n",
    "    # a. Encode the 'Material' column\n",
    "    try:\n",
    "        X_new['Material'] = label_encoder.transform(X_new['Material'])\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Could not encode the 'Material' column. It may contain a material not seen during training.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return\n",
    "\n",
    "    # b. Scale the features\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    # --- 4. Make Predictions ---\n",
    "    print(\"\\n--- Making Predictions on New Data ---\")\n",
    "    y_pred_new = model.predict(X_new_scaled)\n",
    "    print(\"Predictions generated successfully.\")\n",
    "\n",
    "    # --- 5. Evaluate and Report Performance ---\n",
    "    print(\"\\n--- Performance Report on New Data ---\")\n",
    "\n",
    "    # a. Regression Metrics\n",
    "    r2 = r2_score(y_new, y_pred_new)\n",
    "    mae = mean_absolute_error(y_new, y_pred_new)\n",
    "    rmse = np.sqrt(mean_squared_error(y_new, y_pred_new))\n",
    "\n",
    "    print(f\"R-squared (R²) Score: {r2:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f} mm\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} mm\")\n",
    "\n",
    "    # b. 'Proxy' Pass/Fail Accuracy\n",
    "    allowable_deflection = X_new['L (mm)'] / 240\n",
    "    actual_status = np.where(y_new.values < allowable_deflection.values, 'PASS', 'FAIL')\n",
    "    predicted_status = np.where(y_pred_new < allowable_deflection.values, 'PASS', 'FAIL')\n",
    "    \n",
    "    pass_fail_accuracy = accuracy_score(actual_status, predicted_status)\n",
    "    print(f\"\\n'Proxy' Pass/Fail Decision Accuracy: {pass_fail_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"E:\\MS_AI\\BKW_hack\\BKW-Design-Agent\\ML_model\\data\\extracted_historical_data_00.csv\"\n",
    "    try:\n",
    "        test_data = pd.read_csv(file_path)\n",
    "        print(\"CSV file loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file was not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    # Run the evaluation\n",
    "    evaluate_model(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f12cf",
   "metadata": {},
   "source": [
    "to return filtered excel based on length, material type, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_min_volume_pass(output_excel):\n",
    "    \"\"\"\n",
    "    Reads beam data, filters only rows with PASS status, and for each (L, Material)\n",
    "    keeps the row with the minimum Volume (V).\n",
    "    Saves the filtered result to a new CSV file.\n",
    "    \"\"\"\n",
    "    file_path = '/content/drive/MyDrive/extracted_historical_data_00.csv'\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(df.shape)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file was not found at {file_path}\")\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Filter only PASS rows\n",
    "    df_pass = df[df['Status'].str.upper() == 'PASS']\n",
    "\n",
    "    # Select minimum volume per (L (mm), Material)\n",
    "    df_min_vol = (\n",
    "        df_pass.loc[\n",
    "            df_pass.groupby(['L (mm)', 'Material'])['V (mm^3)'].idxmin()\n",
    "        ]\n",
    "        .sort_values(['L (mm)', 'Material'])\n",
    "    )\n",
    "\n",
    "    # Save to new CSV\n",
    "    # df_min_vol.to_excel(output_excel, index=False)\n",
    "    print(f\"Filtered Excel file saved to: {output_excel}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7753589",
   "metadata": {},
   "source": [
    "returns Json and text files, for material and length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e837bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_beam_json_and_row(excel_path, material, length, json_out, text_out):\n",
    "    \"\"\"\n",
    "    Reads the filtered Excel file and returns:\n",
    "      1. JSON file containing key parameters (Material, L, h, w, F)\n",
    "      2. Text file containing the entire row data\n",
    "\n",
    "    Args:\n",
    "        excel_path (str): Path to Excel file\n",
    "        material (str): Material type to search\n",
    "        length (int or float): Beam length\n",
    "        json_out (str): Path to save JSON output\n",
    "        text_out (str): Path to save text file output\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(excel_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    row = df[(df['Material'] == material) & (df['L (mm)'] == length)]\n",
    "\n",
    "    if row.empty:\n",
    "        msg = f\"No matching entry found for Material={material}, L={length}\"\n",
    "        with open(text_out, \"w\") as f:\n",
    "            f.write(msg)\n",
    "        return json.dumps({\"error\": msg}, indent=4)\n",
    "\n",
    "    # Extract required fields for JSON\n",
    "    data_json = row.iloc[0][['Material', 'L (mm)', 'h (mm)', 'w (mm)', 'F (N)']].to_dict()\n",
    "\n",
    "    # Save JSON file\n",
    "    with open(json_out, \"w\") as f:\n",
    "        json.dump(data_json, f, indent=4)\n",
    "\n",
    "    # Save entire row to text file\n",
    "    with open(text_out, \"w\") as f:\n",
    "        f.write(row.to_string(index=False))\n",
    "\n",
    "    print(f\"JSON saved to: {json_out}\")\n",
    "    print(f\"Full row saved to: {text_out}\")\n",
    "\n",
    "    return data_json\n",
    "\n",
    "get_beam_json_and_row(\n",
    "    \"beam_data_filtered.xlsx\",\n",
    "    \"Steel\",\n",
    "    1500,\n",
    "    \"beam_steel_1500.json\",\n",
    "    \"beam_steel_1500.txt\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BKW-Design-Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
